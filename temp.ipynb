{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gplearn.utils import check_random_state\n",
    "\n",
    "\n",
    "rng = check_random_state(0)\n",
    "\n",
    "# Training samples\n",
    "X_train = rng.uniform(-1, 1, 100).reshape(50, 2)\n",
    "y_train = X_train[:, 0] * X_train[:, 1] + X_train[:, 1] - 1\n",
    "# print(\"shapes:\", X_train.shape, y_train.shape)\n",
    "\n",
    "# Testing samples\n",
    "X_test = rng.uniform(-1, 1, 100).reshape(50, 2)\n",
    "y_test = X_test[:, 0] * X_test[:, 1] + X_test[:, 1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgplearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenetic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SymbolicRegressor\n\u001b[1;32m      4\u001b[0m est_gp \u001b[38;5;241m=\u001b[39m SymbolicRegressor(population_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      5\u001b[0m                            generations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, stopping_criteria\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m      6\u001b[0m                            init_depth\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m                            max_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     11\u001b[0m                            parsimony_coefficient\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mest_gp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 1. Todo: make executable program have input for constants\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# automatische differentation (execute)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Auswertung: gegeben zeitbudget: GN-verfahren gegen populationsgröße, was performt besser?\u001b[39;00m\n",
      "File \u001b[0;32m~/gplearn/gplearn/genetic.py:482\u001b[0m, in \u001b[0;36mBaseSymbolic.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m n_jobs, n_programs, starts \u001b[38;5;241m=\u001b[39m _partition_estimators(\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m    480\u001b[0m seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation_size)\n\u001b[0;32m--> 482\u001b[0m population \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_evolve\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_programs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mparents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m                              \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m                              \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Reduce, maintaining order across different n_jobs\u001b[39;00m\n\u001b[1;32m    494\u001b[0m population \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(population))\n",
      "File \u001b[0;32m~/gplearn/.venv/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/gplearn/.venv/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/gplearn/gplearn/genetic.py:148\u001b[0m, in \u001b[0;36m_parallel_evolve\u001b[0;34m(n_programs, parents, X, y, sample_weight, seeds, params)\u001b[0m\n\u001b[1;32m    145\u001b[0m oob_sample_weight[indices] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_optimize_constants\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 148\u001b[0m     program\u001b[38;5;241m.\u001b[39mraw_fitness_ \u001b[38;5;241m=\u001b[39m \u001b[43mprogram\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimized_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     program\u001b[38;5;241m.\u001b[39mraw_fitness_ \u001b[38;5;241m=\u001b[39m program\u001b[38;5;241m.\u001b[39mraw_fitness(X, y, curr_sample_weight)\n",
      "File \u001b[0;32m~/gplearn/gplearn/_program.py:539\u001b[0m, in \u001b[0;36m_Program.optimized_fitness\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    536\u001b[0m initial_constants \u001b[38;5;241m=\u001b[39m [node \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogram \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, \u001b[38;5;28mfloat\u001b[39m)]\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_constants:\n\u001b[0;32m--> 539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mleast_squares\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_constants\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#, method=\"lm\", verbose=2, ftol=10e-4, gtol=10e-4, xtol=10e-4, jac=\"cs\")\u001b[39;00m\n\u001b[1;32m    540\u001b[0m     optimized_constants \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mx\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;66;03m# Update the program with optimized constants\u001b[39;00m\n",
      "File \u001b[0;32m~/gplearn/.venv/lib/python3.12/site-packages/scipy/optimize/_lsq/least_squares.py:832\u001b[0m, in \u001b[0;36mleast_squares\u001b[0;34m(fun, x0, jac, bounds, method, ftol, xtol, gtol, x_scale, loss, f_scale, diff_step, tr_solver, tr_options, jac_sparsity, max_nfev, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun_wrapped\u001b[39m(x):\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39matleast_1d(fun(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m--> 832\u001b[0m f0 \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f0\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fun` must return at most 1-d array_like. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    836\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf0.shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf0\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/gplearn/.venv/lib/python3.12/site-packages/scipy/optimize/_lsq/least_squares.py:830\u001b[0m, in \u001b[0;36mleast_squares.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun_wrapped\u001b[39m(x):\n\u001b[0;32m--> 830\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39matleast_1d(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/gplearn/gplearn/_program.py:530\u001b[0m, in \u001b[0;36m_Program.optimized_fitness.<locals>.objective\u001b[0;34m(constants)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(constants):\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;66;03m# const_idx = 0\u001b[39;00m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;66;03m# for i, node in enumerate(self.program):\u001b[39;00m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;66;03m#     if isinstance(node, float):\u001b[39;00m\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;66;03m#         self.program[i] = constants[const_idx]\u001b[39;00m\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;66;03m#         const_idx += 1\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer:\n\u001b[1;32m    532\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(y_pred)\n",
      "File \u001b[0;32m~/gplearn/gplearn/_program.py:507\u001b[0m, in \u001b[0;36m_Program.build_callable_program.<locals>.<lambda>\u001b[0;34m(X, constants)\u001b[0m\n\u001b[1;32m    504\u001b[0m terminals \u001b[38;5;241m=\u001b[39m apply_stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# turn terminals into lambdas\u001b[39;00m\n\u001b[1;32m    506\u001b[0m intermediate_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m X, constants: function(\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;241m*\u001b[39m[\u001b[43mtranslate_terminal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m terminals])\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(apply_stack) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    509\u001b[0m     apply_stack\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[0;32m~/gplearn/gplearn/_program.py:507\u001b[0m, in \u001b[0;36m_Program.build_callable_program.<locals>.<lambda>\u001b[0;34m(X, constants)\u001b[0m\n\u001b[1;32m    504\u001b[0m terminals \u001b[38;5;241m=\u001b[39m apply_stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# turn terminals into lambdas\u001b[39;00m\n\u001b[1;32m    506\u001b[0m intermediate_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m X, constants: function(\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;241m*\u001b[39m[\u001b[43mtranslate_terminal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m terminals])\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(apply_stack) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    509\u001b[0m     apply_stack\u001b[38;5;241m.\u001b[39mpop()\n",
      "    \u001b[0;31m[... skipping similar frames: _Program.build_callable_program.<locals>.<lambda> at line 507 (2966 times)]\u001b[0m\n",
      "File \u001b[0;32m~/gplearn/gplearn/_program.py:507\u001b[0m, in \u001b[0;36m_Program.build_callable_program.<locals>.<lambda>\u001b[0;34m(X, constants)\u001b[0m\n\u001b[1;32m    504\u001b[0m terminals \u001b[38;5;241m=\u001b[39m apply_stack[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# turn terminals into lambdas\u001b[39;00m\n\u001b[1;32m    506\u001b[0m intermediate_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m X, constants: function(\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;241m*\u001b[39m[\u001b[43mtranslate_terminal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m)\u001b[49m(X, constants) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m terminals])\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(apply_stack) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    509\u001b[0m     apply_stack\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "from gplearn.genetic import SymbolicRegressor\n",
    "\n",
    "\n",
    "est_gp = SymbolicRegressor(population_size=100,\n",
    "                           generations=20, stopping_criteria=0.01,\n",
    "                           init_depth=(2, 5),\n",
    "                           optimize_constants=True,\n",
    "                           p_crossover=0.7, p_subtree_mutation=0.1,\n",
    "                           p_hoist_mutation=0.05, p_point_mutation=0.1,\n",
    "                           max_samples=0.9, verbose=1,\n",
    "                           parsimony_coefficient=0.01, random_state=42)\n",
    "# est_gp.fit(X_train, y_train)\n",
    "\n",
    "# 1. Todo: make executable program have input for constants\n",
    "\n",
    "# automatische differentation (execute)\n",
    "# JIT compiler for execute\n",
    "# stop random variables mutation\n",
    "# use leaset squres sparringly \n",
    "#   (wenige iterationen, grobe Toleranzen, residuen skalieren um größenordnungen zu normalisieren)\n",
    "\n",
    "# Auswertung: gegeben zeitbudget: GN-verfahren gegen populationsgröße, was performt besser?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[<gplearn.functions._Function object at 0x7f47244e8230>], [<gplearn.functions._Function object at 0x7f4724566660>, 0, 1]]\n",
      "[[<gplearn.functions._Function object at 0x7f47244e8230>, <function TestProgram.build_callable_program.<locals>.<lambda> at 0x7f471fb444a0>], [<gplearn.functions._Function object at 0x7f472442f920>, 1, 0.5]]\n",
      "[[<gplearn.functions._Function object at 0x7f47244e8230>, <function TestProgram.build_callable_program.<locals>.<lambda> at 0x7f471fb444a0>, <function TestProgram.build_callable_program.<locals>.<lambda> at 0x7f471fb45300>]]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from gplearn.functions import _Function\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "class TestProgram(object):\n",
    "    def __init__(self, transformer=None, metric=None):\n",
    "        self.transformer = transformer\n",
    "        self.metric = metric\n",
    "        self.function = None\n",
    "        self.raw_fitness = None\n",
    "        add2 = _Function(function=np.add, name='add', arity=2)\n",
    "        sub2 = _Function(function=np.subtract, name='sub', arity=2)\n",
    "        mul2 = _Function(function=np.multiply, name='mul', arity=2)  \n",
    "        # y_test = X_test[:, 0] * X_test[:, 1] + X_test[:, 1] - 1  \n",
    "        self.program = [add2, mul2, 0, 1, sub2, 1, 0.5]\n",
    "    \n",
    "    def build_callable_program(self):\n",
    "        # compiles single terminals, usable for lambdas\n",
    "        constant_counter = itertools.count()    \n",
    "        def translate_terminal(terminal, constants):\n",
    "            if isinstance(terminal, int):\n",
    "                return lambda X: X[:, terminal]\n",
    "            if isinstance(terminal, float):\n",
    "                return lambda X: np.repeat(constants[next(constant_counter)], X.shape[0])\n",
    "            if callable(terminal):\n",
    "                return lambda X, constants: terminal(X, constants)\n",
    "            \n",
    "\n",
    "        # Check for single-node programs\n",
    "        node = self.program[0]\n",
    "        if isinstance(node, float):\n",
    "            return lambda X: np.repeat(node, X.shape[0])\n",
    "        if isinstance(node, int):\n",
    "            return lambda X: X[:, node]\n",
    "\n",
    "        apply_stack = []\n",
    "\n",
    "        for node in self.program:\n",
    "            if isinstance(node, _Function):\n",
    "                apply_stack.append([node])\n",
    "            else:\n",
    "                # Lazily evaluate later\n",
    "                apply_stack[-1].append(node)\n",
    "            \n",
    "            while len(apply_stack[-1]) == apply_stack[-1][0].arity + 1:\n",
    "                # Apply functions that have sufficient arguments\n",
    "                print(apply_stack)\n",
    "                function = apply_stack[-1][0]\n",
    "                terminals = apply_stack[-1][1:]\n",
    "                # turn terminals into lambdas\n",
    "                intermediate_function = lambda X, constants: function(\n",
    "                    *[translate_terminal(t, constants)(X, constants) for t in terminals])\n",
    "                if len(apply_stack) != 1:\n",
    "                    apply_stack.pop()\n",
    "                    apply_stack[-1].append(intermediate_function)\n",
    "                else:\n",
    "                    return intermediate_function\n",
    "\n",
    "        \n",
    "    def optimized_fitness(self, X, y, sample_weight):\n",
    "        # Check for single-node programs\n",
    "        # time0 = time.time()\n",
    "        node = self.program[0]\n",
    "        if isinstance(node, float) or isinstance(node, int):\n",
    "            return self.raw_fitness(X, y, sample_weight)\n",
    "        \n",
    "        self.function = self.build_callable_program()\n",
    "        \n",
    "        # build objective function for optimization\n",
    "        def objective(constants):\n",
    "            y_pred = self.function(X, constants)\n",
    "            if self.transformer:\n",
    "                y_pred = self.transformer(y_pred)\n",
    "            return self.metric(y, y_pred, sample_weight)\n",
    "\n",
    "        # Extract initial constants from the program\n",
    "        initial_constants = [node for node in self.program if isinstance(node, float)]\n",
    "\n",
    "        if initial_constants:\n",
    "            result = least_squares(objective, initial_constants) #, method=\"lm\", verbose=2, ftol=10e-4, gtol=10e-4, xtol=10e-4, jac=\"cs\")\n",
    "            optimized_constants = result.x\n",
    "            print(\"optimized constants:\", optimized_constants)\n",
    "\n",
    "            # Update the program with optimized constants\n",
    "            const_idx = 0\n",
    "            for i, node in enumerate(self.program):\n",
    "                if isinstance(node, float):\n",
    "                    self.program[i] = optimized_constants[const_idx]\n",
    "                    const_idx += 1\n",
    "\n",
    "            # time1 = time.time()\n",
    "            # if time1 - time0 > 2:\n",
    "            # print(f'Optimized fitness took {time1 - time0} seconds')\n",
    "            fitness = result.fun[0]\n",
    "            # print(type(fitness))\n",
    "            return fitness\n",
    "        else:\n",
    "            fitness = self.raw_fitness(X, y, sample_weight)\n",
    "            # print(\"no constants to optimize for\")\n",
    "            return fitness\n",
    "\n",
    "        # optimized_fitness = self.raw_fitness(X, y, sample_weight)\n",
    "        # print(f'Unoptimized fitness: {unoptimized_fitness}')\n",
    "        # print(f'Optimized fitness: {optimized_fitness}')\n",
    "\n",
    "program = TestProgram()\n",
    "test_fit = program.optimized_fitness(X_train, y_train, None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
